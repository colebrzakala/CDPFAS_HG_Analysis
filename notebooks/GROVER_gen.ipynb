{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "060e6a09",
   "metadata": {},
   "source": [
    "# GROVER Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab78d6c",
   "metadata": {},
   "source": [
    "This notebook outlines how the GROVER features were generated for the host and guest pairs. Due to package compatibility issues, this notebook cannot run with the provided virtual environment. To use this notebook, create a separate virtual environment that contains the \"grover\" library and associated dependencies. For more information on the \"grover\" library, see the below resource.\n",
    "\n",
    "[GROVER Repository](https://github.com/tencent-ailab/grover)\n",
    "\n",
    "\n",
    "For external dataset GROVER feature generation, file paths can be replaced with the appropriate .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d14bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['state_dict', 'args'])\n",
      "Namespace(embedding_output_type='both', backbone='dualtrans', hidden_size=1200, bias=False, depth=6, activation='PReLU', undirected=False, weight_decay=2e-07, select_by_loss=True, skip_epoch=0, no_attach_fea=True, dist_coff=0.1, bond_drop_rate=0, input_layer='fc', num_attn_head=4, num_mt_block=1, dense=False, self_attention=False, fine_tune_coff=1)\n",
      "odict_keys(['grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight', 'grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight', 'grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight', 'grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight', 'grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight', 'grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight', 'grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight', 'grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight', 'grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight', 'grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight', 'grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight', 'grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight', 'grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight', 'grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight', 'grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight', 'grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight', 'grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight', 'grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight', 'grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight', 'grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight', 'grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight', 'grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight', 'grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight', 'grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight', 'grover.encoders.edge_blocks.0.act_func.weight', 'grover.encoders.edge_blocks.0.layernorm.weight', 'grover.encoders.edge_blocks.0.layernorm.bias', 'grover.encoders.edge_blocks.0.W_i.weight', 'grover.encoders.edge_blocks.0.attn.linear_layers.0.weight', 'grover.encoders.edge_blocks.0.attn.linear_layers.0.bias', 'grover.encoders.edge_blocks.0.attn.linear_layers.1.weight', 'grover.encoders.edge_blocks.0.attn.linear_layers.1.bias', 'grover.encoders.edge_blocks.0.attn.linear_layers.2.weight', 'grover.encoders.edge_blocks.0.attn.linear_layers.2.bias', 'grover.encoders.edge_blocks.0.attn.output_linear.weight', 'grover.encoders.edge_blocks.0.W_o.weight', 'grover.encoders.edge_blocks.0.sublayer.norm.weight', 'grover.encoders.edge_blocks.0.sublayer.norm.bias', 'grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight', 'grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight', 'grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight', 'grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight', 'grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight', 'grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight', 'grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight', 'grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight', 'grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight', 'grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight', 'grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight', 'grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight', 'grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight', 'grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight', 'grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight', 'grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight', 'grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight', 'grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight', 'grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight', 'grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight', 'grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight', 'grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight', 'grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight', 'grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight', 'grover.encoders.node_blocks.0.act_func.weight', 'grover.encoders.node_blocks.0.layernorm.weight', 'grover.encoders.node_blocks.0.layernorm.bias', 'grover.encoders.node_blocks.0.W_i.weight', 'grover.encoders.node_blocks.0.attn.linear_layers.0.weight', 'grover.encoders.node_blocks.0.attn.linear_layers.0.bias', 'grover.encoders.node_blocks.0.attn.linear_layers.1.weight', 'grover.encoders.node_blocks.0.attn.linear_layers.1.bias', 'grover.encoders.node_blocks.0.attn.linear_layers.2.weight', 'grover.encoders.node_blocks.0.attn.linear_layers.2.bias', 'grover.encoders.node_blocks.0.attn.output_linear.weight', 'grover.encoders.node_blocks.0.W_o.weight', 'grover.encoders.node_blocks.0.sublayer.norm.weight', 'grover.encoders.node_blocks.0.sublayer.norm.bias', 'grover.encoders.ffn_atom_from_atom.W_1.weight', 'grover.encoders.ffn_atom_from_atom.W_1.bias', 'grover.encoders.ffn_atom_from_atom.W_2.weight', 'grover.encoders.ffn_atom_from_atom.W_2.bias', 'grover.encoders.ffn_atom_from_atom.act_func.weight', 'grover.encoders.ffn_atom_from_bond.W_1.weight', 'grover.encoders.ffn_atom_from_bond.W_1.bias', 'grover.encoders.ffn_atom_from_bond.W_2.weight', 'grover.encoders.ffn_atom_from_bond.W_2.bias', 'grover.encoders.ffn_atom_from_bond.act_func.weight', 'grover.encoders.ffn_bond_from_atom.W_1.weight', 'grover.encoders.ffn_bond_from_atom.W_1.bias', 'grover.encoders.ffn_bond_from_atom.W_2.weight', 'grover.encoders.ffn_bond_from_atom.W_2.bias', 'grover.encoders.ffn_bond_from_atom.act_func.weight', 'grover.encoders.ffn_bond_from_bond.W_1.weight', 'grover.encoders.ffn_bond_from_bond.W_1.bias', 'grover.encoders.ffn_bond_from_bond.W_2.weight', 'grover.encoders.ffn_bond_from_bond.W_2.bias', 'grover.encoders.ffn_bond_from_bond.act_func.weight', 'grover.encoders.atom_from_atom_sublayer.norm.weight', 'grover.encoders.atom_from_atom_sublayer.norm.bias', 'grover.encoders.atom_from_bond_sublayer.norm.weight', 'grover.encoders.atom_from_bond_sublayer.norm.bias', 'grover.encoders.bond_from_atom_sublayer.norm.weight', 'grover.encoders.bond_from_atom_sublayer.norm.bias', 'grover.encoders.bond_from_bond_sublayer.norm.weight', 'grover.encoders.bond_from_bond_sublayer.norm.bias', 'grover.encoders.act_func_node.weight', 'grover.encoders.act_func_edge.weight'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from grover.task.fingerprint import generate_fingerprints\n",
    "import numpy as np\n",
    "from grover.util.utils import create_logger\n",
    "\n",
    "# Step 1: Load the checkpoint (assumes you have both 'state_dict' and 'args' saved)\n",
    "checkpoint_path = \"grover_large.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "# Print the keys and args in the checkpoint\n",
    "print(checkpoint.keys())\n",
    "print(checkpoint[\"args\"])\n",
    "print(checkpoint[\"state_dict\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edadc61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weight tensor shapes:\n",
      "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.act_func.weight: (1,)\n",
      "grover.encoders.edge_blocks.0.layernorm.weight: (1200,)\n",
      "grover.encoders.edge_blocks.0.layernorm.bias: (1200,)\n",
      "grover.encoders.edge_blocks.0.W_i.weight: (1200, 165)\n",
      "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias: (1200,)\n",
      "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias: (1200,)\n",
      "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias: (1200,)\n",
      "grover.encoders.edge_blocks.0.attn.output_linear.weight: (1200, 1200)\n",
      "grover.encoders.edge_blocks.0.W_o.weight: (1200, 4800)\n",
      "grover.encoders.edge_blocks.0.sublayer.norm.weight: (1200,)\n",
      "grover.encoders.edge_blocks.0.sublayer.norm.bias: (1200,)\n",
      "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.act_func.weight: (1,)\n",
      "grover.encoders.node_blocks.0.layernorm.weight: (1200,)\n",
      "grover.encoders.node_blocks.0.layernorm.bias: (1200,)\n",
      "grover.encoders.node_blocks.0.W_i.weight: (1200, 151)\n",
      "grover.encoders.node_blocks.0.attn.linear_layers.0.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.attn.linear_layers.0.bias: (1200,)\n",
      "grover.encoders.node_blocks.0.attn.linear_layers.1.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.attn.linear_layers.1.bias: (1200,)\n",
      "grover.encoders.node_blocks.0.attn.linear_layers.2.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.attn.linear_layers.2.bias: (1200,)\n",
      "grover.encoders.node_blocks.0.attn.output_linear.weight: (1200, 1200)\n",
      "grover.encoders.node_blocks.0.W_o.weight: (1200, 4800)\n",
      "grover.encoders.node_blocks.0.sublayer.norm.weight: (1200,)\n",
      "grover.encoders.node_blocks.0.sublayer.norm.bias: (1200,)\n",
      "grover.encoders.ffn_atom_from_atom.W_1.weight: (4800, 1351)\n",
      "grover.encoders.ffn_atom_from_atom.W_1.bias: (4800,)\n",
      "grover.encoders.ffn_atom_from_atom.W_2.weight: (1200, 4800)\n",
      "grover.encoders.ffn_atom_from_atom.W_2.bias: (1200,)\n",
      "grover.encoders.ffn_atom_from_atom.act_func.weight: (1,)\n",
      "grover.encoders.ffn_atom_from_bond.W_1.weight: (4800, 1351)\n",
      "grover.encoders.ffn_atom_from_bond.W_1.bias: (4800,)\n",
      "grover.encoders.ffn_atom_from_bond.W_2.weight: (1200, 4800)\n",
      "grover.encoders.ffn_atom_from_bond.W_2.bias: (1200,)\n",
      "grover.encoders.ffn_atom_from_bond.act_func.weight: (1,)\n",
      "grover.encoders.ffn_bond_from_atom.W_1.weight: (4800, 1365)\n",
      "grover.encoders.ffn_bond_from_atom.W_1.bias: (4800,)\n",
      "grover.encoders.ffn_bond_from_atom.W_2.weight: (1200, 4800)\n",
      "grover.encoders.ffn_bond_from_atom.W_2.bias: (1200,)\n",
      "grover.encoders.ffn_bond_from_atom.act_func.weight: (1,)\n",
      "grover.encoders.ffn_bond_from_bond.W_1.weight: (4800, 1365)\n",
      "grover.encoders.ffn_bond_from_bond.W_1.bias: (4800,)\n",
      "grover.encoders.ffn_bond_from_bond.W_2.weight: (1200, 4800)\n",
      "grover.encoders.ffn_bond_from_bond.W_2.bias: (1200,)\n",
      "grover.encoders.ffn_bond_from_bond.act_func.weight: (1,)\n",
      "grover.encoders.atom_from_atom_sublayer.norm.weight: (1200,)\n",
      "grover.encoders.atom_from_atom_sublayer.norm.bias: (1200,)\n",
      "grover.encoders.atom_from_bond_sublayer.norm.weight: (1200,)\n",
      "grover.encoders.atom_from_bond_sublayer.norm.bias: (1200,)\n",
      "grover.encoders.bond_from_atom_sublayer.norm.weight: (1200,)\n",
      "grover.encoders.bond_from_atom_sublayer.norm.bias: (1200,)\n",
      "grover.encoders.bond_from_bond_sublayer.norm.weight: (1200,)\n",
      "grover.encoders.bond_from_bond_sublayer.norm.bias: (1200,)\n",
      "grover.encoders.act_func_node.weight: (1,)\n",
      "grover.encoders.act_func_edge.weight: (1,)\n",
      "readout.cached_zero_vector: (1200,)\n",
      "mol_atom_from_atom_ffn.1.weight: (200, 1400)\n",
      "mol_atom_from_atom_ffn.1.bias: (200,)\n",
      "mol_atom_from_atom_ffn.2.weight: (1,)\n",
      "mol_atom_from_atom_ffn.4.weight: (0, 200)\n",
      "mol_atom_from_atom_ffn.4.bias: (0,)\n",
      "mol_atom_from_bond_ffn.1.weight: (200, 1400)\n",
      "mol_atom_from_bond_ffn.1.bias: (200,)\n",
      "mol_atom_from_bond_ffn.2.weight: (1,)\n",
      "mol_atom_from_bond_ffn.4.weight: (0, 200)\n",
      "mol_atom_from_bond_ffn.4.bias: (0,)\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of each weight tensor in the model's state_dict\n",
    "if \"state_dict\" in model:\n",
    "    print(\"Model weight tensor shapes:\")\n",
    "    for key, value in model[\"state_dict\"].items():\n",
    "        if hasattr(value, \"shape\"):\n",
    "            print(f\"{key}: {tuple(value.shape)}\")\n",
    "        else:\n",
    "            print(f\"{key}: Not a tensor or missing shape attribute\")\n",
    "else:\n",
    "    print(\"No state_dict found in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36e4e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed-forward network (ffn) layer weights:\n",
      "Layer: grover.encoders.ffn_atom_from_atom.W_1.weight\n",
      "[[ 4.0252121e-06  8.0301032e-07  1.6447584e-05 ...  8.7161586e-03\n",
      "   2.0930033e-02 -8.8472711e-03]\n",
      " [-3.7588234e-05  3.7492387e-06 -2.2893100e-06 ...  1.4373798e-02\n",
      "  -2.8613904e-02 -2.6396010e-03]\n",
      " [-3.0557545e-05 -1.0276249e-06 -5.7388256e-06 ... -1.9698452e-02\n",
      "  -3.6661640e-02 -1.4618294e-02]\n",
      " ...\n",
      " [-4.2463827e-04  4.3717564e-06  1.4851106e-05 ...  1.6418254e-02\n",
      "   1.0370712e-02 -1.6428720e-02]\n",
      " [ 8.7928111e-06 -2.9649266e-06 -8.3153145e-06 ... -3.2102547e-04\n",
      "  -1.2141189e-02  1.7105579e-02]\n",
      " [ 2.3316417e-03 -1.9217109e-06 -1.3187578e-03 ...  1.0773701e-02\n",
      "  -1.5966428e-02  1.1881495e-02]]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_atom_from_atom.W_2.weight\n",
      "[[-0.00786536 -0.00764744 -0.00880815 ... -0.00339244 -0.00151713\n",
      "   0.00570643]\n",
      " [ 0.00295709 -0.01201642  0.02430255 ...  0.00515964  0.02019144\n",
      "   0.01501802]\n",
      " [ 0.01807962  0.00845418 -0.00142048 ...  0.00823679  0.01387063\n",
      "  -0.00118906]\n",
      " ...\n",
      " [ 0.01270039  0.00918842  0.00773319 ...  0.00033458 -0.01224032\n",
      "   0.0168355 ]\n",
      " [-0.00625746  0.00251597 -0.00824294 ... -0.01727461 -0.00999275\n",
      "  -0.00534872]\n",
      " [ 0.02228145 -0.01331451  0.0107594  ...  0.01199473 -0.0195343\n",
      "  -0.00952717]]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_atom_from_atom.act_func.weight\n",
      "[0.00045668]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_atom_from_bond.W_1.weight\n",
      "[[-5.21422953e-05  4.03304239e-06  6.28563384e-06 ... -8.09794478e-03\n",
      "  -1.00788120e-02  3.18275997e-03]\n",
      " [ 1.74912930e-05  1.87680107e-05  2.56202093e-05 ... -1.90828869e-03\n",
      "  -6.30743615e-03 -1.07734445e-02]\n",
      " [-1.87394635e-05 -7.32182707e-06  1.11484542e-05 ... -1.42862638e-02\n",
      "   1.12861032e-02 -1.13434419e-02]\n",
      " ...\n",
      " [-1.13668313e-04 -2.35398761e-06  2.41792095e-05 ...  2.84224539e-03\n",
      "  -1.34774735e-02  4.30887006e-03]\n",
      " [-1.04014771e-05  8.84981273e-06  1.93207889e-05 ...  1.19756057e-03\n",
      "  -8.20430275e-03  4.13581124e-03]\n",
      " [ 2.53389648e-04  4.70499253e-06 -6.77956734e-04 ... -7.71508692e-03\n",
      "   7.49436673e-03 -3.04179126e-03]]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_atom_from_bond.W_2.weight\n",
      "[[ 0.00283898  0.01801801 -0.01242316 ... -0.01595797 -0.0120217\n",
      "   0.02449786]\n",
      " [-0.01349892  0.00490442 -0.0017186  ...  0.01118453 -0.00177147\n",
      "   0.02144155]\n",
      " [ 0.0017329   0.00547635 -0.00067768 ...  0.02079853 -0.0132815\n",
      "  -0.00610015]\n",
      " ...\n",
      " [ 0.00082755  0.02385376  0.00050521 ... -0.00359442  0.00567629\n",
      "  -0.00431192]\n",
      " [-0.01011107  0.00851128 -0.0072555  ... -0.00571052 -0.01111244\n",
      "  -0.00201032]\n",
      " [ 0.0096371  -0.01003957 -0.00465599 ... -0.00855142  0.01196433\n",
      "  -0.00217242]]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_atom_from_bond.act_func.weight\n",
      "[0.00057091]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_bond_from_atom.W_1.weight\n",
      "[[-4.4648687e-06  7.9412525e-32 -1.5527941e-07 ...  3.9421894e-02\n",
      "   8.9341253e-03  6.9541787e-03]\n",
      " [-1.3418880e-05  2.9029271e-32 -4.2338996e-07 ... -1.0319714e-02\n",
      "  -6.6970526e-03 -1.8569561e-02]\n",
      " [ 4.0619308e-03 -2.2067458e-32  1.3539722e-07 ...  5.2924561e-03\n",
      "  -7.0534390e-03 -1.6170391e-03]\n",
      " ...\n",
      " [ 4.5069683e-05  1.2204142e-31 -1.5652306e-06 ... -9.7366789e-04\n",
      "  -3.8018066e-04 -1.2593842e-03]\n",
      " [-2.9266650e-05  2.0300371e-31 -1.6324278e-06 ...  4.1644715e-02\n",
      "  -1.9601658e-02 -3.9916779e-03]\n",
      " [ 8.8624229e-06 -7.0203015e-32 -4.5935278e-07 ... -2.3175067e-04\n",
      "  -1.6419965e-04 -7.8473837e-05]]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_bond_from_atom.W_2.weight\n",
      "[[ 7.6522301e-03 -1.9310438e-04  5.2859019e-03 ...  2.3111429e-03\n",
      "  -9.2667394e-04  8.2944258e-04]\n",
      " [ 3.4554556e-02 -1.8304318e-02  9.4145220e-03 ... -2.2220300e-04\n",
      "  -6.4345330e-02  1.0523304e-06]\n",
      " [ 4.7563110e-03 -9.7591951e-03  7.8458013e-03 ...  1.1634335e-03\n",
      "  -5.5451444e-03  3.7695281e-04]\n",
      " ...\n",
      " [ 5.7442147e-02 -1.7477766e-04  2.5727877e-02 ...  3.5994924e-03\n",
      "   9.9228099e-03  1.5871213e-03]\n",
      " [-6.7406632e-03  6.8322942e-02 -2.0269722e-02 ... -8.7902963e-04\n",
      "  -6.3701514e-03 -2.2915253e-04]\n",
      " [ 5.7859123e-03  9.3062213e-03 -4.8660982e-04 ...  1.8501775e-03\n",
      "   1.3747360e-02 -1.0383833e-03]]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_bond_from_atom.act_func.weight\n",
      "[8.862914e-05]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_bond_from_bond.W_1.weight\n",
      "[[ 1.4263115e-04 -1.3012809e-31 -1.0242123e-05 ...  5.2466444e-03\n",
      "  -2.1859545e-02  2.8874483e-03]\n",
      " [-2.4717272e-05 -2.6893207e-31  1.4178681e-06 ...  1.9114604e-02\n",
      "  -2.9185659e-03 -9.0805590e-03]\n",
      " [ 4.5840603e-05  1.6417816e-31 -2.8766444e-06 ... -1.0679986e-02\n",
      "   1.0894327e-02  2.1612614e-03]\n",
      " ...\n",
      " [-1.5898438e-06 -1.2603980e-31  3.4294354e-07 ... -2.1607881e-02\n",
      "  -3.6324649e-03  6.9977192e-04]\n",
      " [-8.6067994e-06  3.3677304e-31 -7.1933805e-06 ... -3.2873735e-02\n",
      "  -5.6457100e-03  3.2884825e-03]\n",
      " [-2.7562082e-06 -1.8145668e-31  1.5025213e-06 ... -8.8920295e-03\n",
      "   7.3696394e-03 -1.1153688e-02]]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_bond_from_bond.W_2.weight\n",
      "[[ 0.00125191 -0.00351347  0.01310558 ... -0.01954408  0.0095764\n",
      "   0.00368523]\n",
      " [ 0.00112852 -0.01013765 -0.01435196 ...  0.00191893  0.0053767\n",
      "   0.01864949]\n",
      " [-0.01285817  0.00516389  0.00290381 ...  0.0146577  -0.00154493\n",
      "  -0.00714191]\n",
      " ...\n",
      " [-0.03128665 -0.00220142  0.00812108 ...  0.02516992  0.01147209\n",
      "  -0.01019868]\n",
      " [-0.01535461 -0.01232684  0.00314945 ... -0.02790734  0.02333895\n",
      "   0.00142634]\n",
      " [ 0.00487271  0.0160365  -0.06667315 ... -0.00599857 -0.02563959\n",
      "  -0.0574404 ]]\n",
      "------------------------------------------------------------\n",
      "Layer: grover.encoders.ffn_bond_from_bond.act_func.weight\n",
      "[0.00033148]\n",
      "------------------------------------------------------------\n",
      "Layer: mol_atom_from_atom_ffn.1.weight\n",
      "[[ 0.01327825  0.01023374 -0.05015666 ...  0.03806127  0.072332\n",
      "   0.0158124 ]\n",
      " [ 0.01458701  0.03717027 -0.07758924 ...  0.0190975   0.01520475\n",
      "   0.04742151]\n",
      " [-0.0087315   0.05290148  0.02157088 ... -0.03404567 -0.07558183\n",
      "  -0.02938156]\n",
      " ...\n",
      " [-0.01861493 -0.01977758  0.0147217  ...  0.0312067   0.08371088\n",
      "   0.02341428]\n",
      " [-0.0234985  -0.00345784  0.03859008 ... -0.02352837 -0.01855867\n",
      "   0.03048788]\n",
      " [-0.02170291 -0.05185311 -0.00793967 ... -0.0110621   0.02441922\n",
      "  -0.02403482]]\n",
      "------------------------------------------------------------\n",
      "Layer: mol_atom_from_atom_ffn.2.weight\n",
      "[0.]\n",
      "------------------------------------------------------------\n",
      "Layer: mol_atom_from_atom_ffn.4.weight\n",
      "[]\n",
      "------------------------------------------------------------\n",
      "Layer: mol_atom_from_bond_ffn.1.weight\n",
      "[[-0.03680102 -0.0478287  -0.03732964 ... -0.00778625 -0.01988737\n",
      "  -0.02287754]\n",
      " [ 0.08164882  0.02082366  0.00834052 ... -0.00772563 -0.0079463\n",
      "  -0.0459729 ]\n",
      " [-0.00996845  0.0782075  -0.01105835 ... -0.00590286  0.03428463\n",
      "   0.04341883]\n",
      " ...\n",
      " [ 0.03650025 -0.04243515  0.02413044 ...  0.03254801 -0.01218044\n",
      "   0.04193411]\n",
      " [ 0.02061169  0.00273161 -0.01273877 ... -0.05368469  0.03930272\n",
      "   0.00425932]\n",
      " [ 0.03031911  0.02276566  0.01790154 ...  0.03355956 -0.04051027\n",
      "   0.08775584]]\n",
      "------------------------------------------------------------\n",
      "Layer: mol_atom_from_bond_ffn.2.weight\n",
      "[0.]\n",
      "------------------------------------------------------------\n",
      "Layer: mol_atom_from_bond_ffn.4.weight\n",
      "[]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the values of the weights in the feed-forward network (ffn) layers of the loaded model\n",
    "\n",
    "# Ensure 'state_dict' exists in the model dictionary\n",
    "if \"state_dict\" not in model:\n",
    "    raise KeyError(\"No 'state_dict' found in the loaded model.\")\n",
    "\n",
    "# Iterate through all keys in the state_dict and print weights for ffn layers\n",
    "print(\"Feed-forward network (ffn) layer weights:\")\n",
    "for key, tensor in model[\"state_dict\"].items():\n",
    "    # Check if the key corresponds to an ffn layer and is a weight tensor\n",
    "    if \"ffn\" in key and \".weight\" in key:\n",
    "        print(f\"Layer: {key}\")\n",
    "        # Validate tensor type\n",
    "        if hasattr(tensor, \"numpy\"):\n",
    "            print(tensor.numpy())\n",
    "        else:\n",
    "            print(\"Tensor does not have a numpy() method.\")\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce14afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model arguments: Namespace(embedding_output_type='both', backbone='dualtrans', hidden_size=1200, bias=False, depth=6, activation='PReLU', undirected=False, weight_decay=2e-07, select_by_loss=True, skip_epoch=0, no_attach_fea=True, dist_coff=0.1, bond_drop_rate=0, input_layer='fc', num_attn_head=4, num_mt_block=1, dense=False, self_attention=False, fine_tune_coff=1, fingerprint_source='both', cuda=False, features_dim=0, dropout=0.0, features_only=False, ffn_num_layers=2, ffn_hidden_size=200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'dataset_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m args\u001b[38;5;241m.\u001b[39moutput_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(args, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Step 4: Initialize the model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# model = GroverFpGeneration(args)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m GroverFinetuneTask(args)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Step 5: Load pretrained weights\u001b[39;00m\n\u001b[0;32m     23\u001b[0m missing, unexpected \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m], strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\grover\\model\\models.py:389\u001b[0m, in \u001b[0;36mGroverFinetuneTask.__init__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmol_atom_from_bond_ffn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_ffn(args)\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m#self.ffn = nn.ModuleList()\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m#self.ffn.append(self.mol_atom_from_atom_ffn)\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m#self.ffn.append(self.mol_atom_from_bond_ffn)\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdataset_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSigmoid()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'dataset_type'"
     ]
    }
   ],
   "source": [
    "from grover.model.models import GroverFpGeneration, GroverFinetuneTask\n",
    "\n",
    "# Step 2: Extract model arguments directly from the checkpoint\n",
    "args = checkpoint[\"args\"]\n",
    "print(\"Model arguments:\", args)\n",
    "\n",
    "# Step 3: Add any missing required fields (optional safety)\n",
    "args.fingerprint_source = getattr(\n",
    "    args, \"fingerprint_source\", \"both\"\n",
    ")  # atom / bond / both\n",
    "args.cuda = getattr(args, \"cuda\", torch.cuda.is_available())\n",
    "args.features_dim = getattr(args, \"features_dim\", 0)\n",
    "args.dropout = getattr(args, \"dropout\", 0.0)\n",
    "args.features_only = getattr(args, \"features_only\", False)\n",
    "args.ffn_num_layers = getattr(args, \"ffn_num_layers\", 2)\n",
    "args.ffn_hidden_size = getattr(args, \"ffn_hidden_size\", 200)\n",
    "args.output_size = getattr(args, \"output_size\", 0)\n",
    "\n",
    "# Step 4: Initialize the model\n",
    "# model = GroverFpGeneration(args)\n",
    "model = GroverFinetuneTask(args)\n",
    "\n",
    "# Step 5: Load pretrained weights\n",
    "missing, unexpected = model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "print(\"Missing keys:\", missing)\n",
    "print(\"Unexpected keys:\", unexpected)\n",
    "\n",
    "\n",
    "# Optional: move to GPU\n",
    "if args.cuda:\n",
    "    model_host = model.cuda()\n",
    "\n",
    "print(\"âœ… Loaded GroverFpGeneration model from checkpoint.\")\n",
    "\n",
    "# Print all model arguments in a readable format\n",
    "if hasattr(args, \"__dict__\"):\n",
    "    print(\"Loaded model arguments:\")\n",
    "    for key, value in vars(args).items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"Model arguments are not in Namespace format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f5e7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved to grover_large_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Save the model checkpoint with state_dict and args\n",
    "checkpoint_to_save = {\"state_dict\": model.state_dict(), \"args\": args}\n",
    "\n",
    "save_path = \"grover_large_checkpoint.pt\"\n",
    "\n",
    "try:\n",
    "    torch.save(checkpoint_to_save, save_path)\n",
    "    print(f\"Model checkpoint saved to {save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model checkpoint: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ed8b5",
   "metadata": {},
   "source": [
    "### Try using Grover fingerprint function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import types\n",
    "from argparse import Namespace\n",
    "from task.fingerprint import generate_fingerprints\n",
    "from grover.util.utils import create_logger\n",
    "import torch\n",
    "\n",
    "# Define your arguments (adjust paths as needed)\n",
    "args = Namespace(\n",
    "    data_path=\"host_smiles.csv\",  # Path to your SMILES CSV\n",
    "    output_path=\"host_fingerprints.npz\",  # Output path for fingerprints\n",
    "    features_path=None,  # Or a list of feature file paths\n",
    "    fingerprint_source=\"both\",  # \"atom\", \"bond\", or \"both\"\n",
    "    checkpoint_paths=[\"grover_large_checkpoint.pt\"],  # List with your model checkpoint\n",
    "    cuda=False,  # Use GPU if available\n",
    "    batch_size=32,  # Batch size for DataLoader\n",
    ")\n",
    "\n",
    "args.fingerprint_source = getattr(\n",
    "    args, \"fingerprint_source\", \"both\"\n",
    ")  # atom / bond / both\n",
    "args.cuda = getattr(args, \"cuda\", torch.cuda.is_available())\n",
    "args.features_dim = getattr(args, \"features_dim\", 0)\n",
    "args.dropout = getattr(args, \"dropout\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b698ebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total size = 3,459\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
      "Loading pretrained parameter \"readout.cached_zero_vector\".\n",
      "c:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\grover\\model\\layers.py:18: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n",
      "c:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\grover\\model\\layers.py:45: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \targs\u001b[38;5;241m.\u001b[39mno_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Default to False if not set\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Generate fingerprints\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m fingerprints \u001b[38;5;241m=\u001b[39m generate_fingerprints(args, logger)\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\task\\fingerprint.py:73\u001b[0m, in \u001b[0;36mgenerate_fingerprints\u001b[1;34m(args, logger)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m     72\u001b[0m model \u001b[38;5;241m=\u001b[39m load_checkpoint(checkpoint_path, cuda\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mcuda, current_args\u001b[38;5;241m=\u001b[39margs, logger\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[1;32m---> 73\u001b[0m model_preds \u001b[38;5;241m=\u001b[39m do_generate(\n\u001b[0;32m     74\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     75\u001b[0m     data\u001b[38;5;241m=\u001b[39mtest_data,\n\u001b[0;32m     76\u001b[0m     args\u001b[38;5;241m=\u001b[39margs\n\u001b[0;32m     77\u001b[0m )\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_preds\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\task\\fingerprint.py:44\u001b[0m, in \u001b[0;36mdo_generate\u001b[1;34m(model, data, args)\u001b[0m\n\u001b[0;32m     42\u001b[0m     _, batch, features_batch, _, _ \u001b[38;5;241m=\u001b[39m item\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 44\u001b[0m         batch_preds \u001b[38;5;241m=\u001b[39m model(batch, features_batch)\n\u001b[0;32m     45\u001b[0m         preds\u001b[38;5;241m.\u001b[39mextend(batch_preds\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\grover\\model\\models.py:332\u001b[0m, in \u001b[0;36mGroverFpGeneration.forward\u001b[1;34m(self, batch, features_batch)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03mThe forward function.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03mIt takes graph batch and molecular feature batch as input and produce the fingerprints of this molecules.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    330\u001b[0m _, _, _, _, _, a_scope, b_scope, _ \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m--> 332\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrover(batch)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# Share readout\u001b[39;00m\n\u001b[0;32m    334\u001b[0m mol_atom_from_bond_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadout(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matom_from_bond\u001b[39m\u001b[38;5;124m\"\u001b[39m], a_scope)\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\grover\\model\\models.py:56\u001b[0m, in \u001b[0;36mGROVEREmbedding.forward\u001b[1;34m(self, graph_batch)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph_batch: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    The forward function takes graph_batch as input and output a dict. The content of the dict is decided by\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    self.embedding_output_type.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    :return: a dict containing the embedding results.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoders(graph_batch)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_output_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124matom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matom_from_atom\u001b[39m\u001b[38;5;124m\"\u001b[39m: output[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matom_from_bond\u001b[39m\u001b[38;5;124m\"\u001b[39m: output[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     59\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbond_from_atom\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbond_from_bond\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}  \u001b[38;5;66;03m# atom_from_atom, atom_from_bond\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\grover\\model\\layers.py:851\u001b[0m, in \u001b[0;36mGTransEncoder.forward\u001b[1;34m(self, batch, features_batch)\u001b[0m\n\u001b[0;32m    849\u001b[0m     node_batch, features_batch \u001b[38;5;241m=\u001b[39m nb(node_batch, features_batch)\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_blocks:  \u001b[38;5;66;03m# bond messages. Multi-headed attention\u001b[39;00m\n\u001b[1;32m--> 851\u001b[0m     edge_batch, features_batch \u001b[38;5;241m=\u001b[39m eb(edge_batch, features_batch)\n\u001b[0;32m    853\u001b[0m atom_output, _, _, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m node_batch  \u001b[38;5;66;03m# atom hidden states\u001b[39;00m\n\u001b[0;32m    854\u001b[0m _, bond_output, _, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m edge_batch  \u001b[38;5;66;03m# bond hidden states\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\Documents\\SYROP\\grover\\grover\\grover\\model\\layers.py:604\u001b[0m, in \u001b[0;36mMTBlock.forward\u001b[1;34m(self, batch, features_batch)\u001b[0m\n\u001b[0;32m    602\u001b[0m x_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(queries, keys, values)  \u001b[38;5;66;03m# multi-headed attention\u001b[39;00m\n\u001b[0;32m    603\u001b[0m x_out \u001b[38;5;241m=\u001b[39m x_out\u001b[38;5;241m.\u001b[39mview(x_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 604\u001b[0m x_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_o(x_out)\n\u001b[0;32m    606\u001b[0m x_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;66;03m# support no residual connection in MTBlock.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\cbrzakala\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a logger (optional)\n",
    "logger = create_logger(\"fingerprint\", save_dir=None, quiet=False)\n",
    "\n",
    "# Ensure 'parser_name' is present in args to avoid AttributeError\n",
    "if not hasattr(args, \"parser_name\"):\n",
    "    args.parser_name = \"fingerprint\"  # or set to the appropriate parser name\n",
    "\n",
    "# Ensure 'no_cache' is present in args to avoid AttributeError in mol2graph\n",
    "if not hasattr(args, \"no_cache\"):\n",
    "    args.no_cache = False  # Default to False if not set\n",
    "\n",
    "# Generate fingerprints\n",
    "fingerprints = generate_fingerprints(args, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9be4581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprints generated and saved to host_fingerprints.npz\n",
      "Shape: (3459, 4800)\n"
     ]
    }
   ],
   "source": [
    "# Save fingerprints if you want\n",
    "import numpy as np\n",
    "\n",
    "np.savez_compressed(args.output_path, fps=fingerprints)\n",
    "\n",
    "print(f\"Fingerprints generated and saved to {args.output_path}\")\n",
    "print(f\"Shape: {np.array(fingerprints).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fdff883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import types\n",
    "from argparse import Namespace\n",
    "from task.fingerprint import generate_fingerprints\n",
    "from grover.util.utils import create_logger\n",
    "import torch\n",
    "\n",
    "# Define your arguments (adjust paths as needed)\n",
    "args = Namespace(\n",
    "    data_path=\"guest_smiles.csv\",  # Path to your SMILES CSV\n",
    "    output_path=\"guest_fingerprints.npz\",  # Output path for fingerprints\n",
    "    features_path=None,  # Or a list of feature file paths\n",
    "    fingerprint_source=\"both\",  # \"atom\", \"bond\", or \"both\"\n",
    "    checkpoint_paths=[\"grover_large_checkpoint.pt\"],  # List with your model checkpoint\n",
    "    cuda=False,  # Use GPU if available\n",
    "    batch_size=32,  # Batch size for DataLoader\n",
    ")\n",
    "\n",
    "args.fingerprint_source = getattr(\n",
    "    args, \"fingerprint_source\", \"both\"\n",
    ")  # atom / bond / both\n",
    "args.cuda = getattr(args, \"cuda\", torch.cuda.is_available())\n",
    "args.features_dim = getattr(args, \"features_dim\", 0)\n",
    "args.dropout = getattr(args, \"dropout\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c395ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total size = 3,459\n",
      "Total size = 3,459\n",
      "Total size = 3,459\n",
      "Total size = 3,459\n",
      "Total size = 3,459\n",
      "Total size = 3,459\n",
      "Generating...\n",
      "Generating...\n",
      "Generating...\n",
      "Generating...\n",
      "Generating...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
      "Loading pretrained parameter \"readout.cached_zero_vector\".\n",
      "Loading pretrained parameter \"readout.cached_zero_vector\".\n",
      "Loading pretrained parameter \"readout.cached_zero_vector\".\n",
      "Loading pretrained parameter \"readout.cached_zero_vector\".\n",
      "Loading pretrained parameter \"readout.cached_zero_vector\".\n",
      "Loading pretrained parameter \"readout.cached_zero_vector\".\n"
     ]
    }
   ],
   "source": [
    "# Create a logger (optional)\n",
    "logger = create_logger(\"fingerprint\", save_dir=None, quiet=False)\n",
    "\n",
    "# Ensure 'parser_name' is present in args to avoid AttributeError\n",
    "if not hasattr(args, \"parser_name\"):\n",
    "    args.parser_name = \"fingerprint\"  # or set to the appropriate parser name\n",
    "\n",
    "# Ensure 'no_cache' is present in args to avoid AttributeError in mol2graph\n",
    "if not hasattr(args, \"no_cache\"):\n",
    "    args.no_cache = False  # Default to False if not set\n",
    "\n",
    "# Generate fingerprints\n",
    "fingerprints = generate_fingerprints(args, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0519b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save fingerprints if you want\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39msavez_compressed(args\u001b[38;5;241m.\u001b[39moutput_path, fps\u001b[38;5;241m=\u001b[39mfingerprints)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFingerprints generated and saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39marray(fingerprints)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# Save fingerprints if you want\n",
    "import numpy as np\n",
    "\n",
    "np.savez_compressed(args.output_path, fps=fingerprints)\n",
    "\n",
    "print(f\"Fingerprints generated and saved to {args.output_path}\")\n",
    "print(f\"Shape: {np.array(fingerprints).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10a223b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined host-guest fingerprints saved to host_guest_fingerprints.csv with shape (3459, 9600)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Concatenate host and guest fingerprints row-wise and save as CSV\n",
    "\n",
    "\n",
    "# Load host and guest fingerprints from .npz files\n",
    "host_npz = np.load(\"host_fingerprints.npz\")\n",
    "guest_npz = np.load(\"guest_fingerprints.npz\")\n",
    "\n",
    "# Extract fingerprint arrays\n",
    "host_fps: np.ndarray = host_npz[\"fps\"]\n",
    "guest_fps: np.ndarray = guest_npz[\"fps\"]\n",
    "\n",
    "# Validate shapes and types\n",
    "if not (isinstance(host_fps, np.ndarray) and isinstance(guest_fps, np.ndarray)):\n",
    "    raise TypeError(\"Fingerprint arrays must be numpy.ndarray.\")\n",
    "if host_fps.shape != guest_fps.shape:\n",
    "    raise ValueError(f\"Shape mismatch: host {host_fps.shape}, guest {guest_fps.shape}\")\n",
    "if host_fps.shape[0] != 3459 or host_fps.shape[1] != 4800:\n",
    "    raise ValueError(f\"Expected shape (3459, 4800), got {host_fps.shape}\")\n",
    "\n",
    "# Concatenate along columns (axis=1)\n",
    "combined_fps: np.ndarray = np.concatenate([host_fps, guest_fps], axis=1)\n",
    "\n",
    "# Convert to DataFrame for CSV output\n",
    "combined_df: pd.DataFrame = pd.DataFrame(combined_fps)\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename: str = \"host_guest_fingerprints.csv\"\n",
    "combined_df.to_csv(csv_filename, index=False, float_format=\"%.8f\")\n",
    "\n",
    "print(\n",
    "    f\"Combined host-guest fingerprints saved to {csv_filename} with shape {combined_df.shape}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
